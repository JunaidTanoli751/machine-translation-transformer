# ğŸŒ Universal Translator - Multilingual Seq2Seq Transformer

[![Python Version](https://img.shields.io/badge/Python-3.8%2B-blue?logo=python&logoColor=white)](https://www.python.org/)
[![Hugging Face](https://img.shields.io/badge/ğŸ¤—%20Hugging%20Face-Transformers-orange)](https://huggingface.co/transformers/)
[![Gradio](https://img.shields.io/badge/Gradio-UI-yellow?logo=gradio&logoColor=white)](https://gradio.app/)
[![HF Space](https://img.shields.io/badge/ğŸ¤—%20Space-Live%20Demo-ff69b4)](https://huggingface.co/spaces/adeeliqbal/universal-translator)

---

## âœ¨ Overview

A Neural Machine Translation system leveraging Meta AI's pretrained **NLLB-200** model for direct many-to-many translation across multiple languages. Features automatic language detection and an interactive Gradio web interface.

### ğŸ¯ Key Features

- **ğŸŒ Multi-Language Support**: 8 languages in UI (English, Urdu, Hindi, French, German, Spanish, Chinese, Arabic)
- **ğŸ§  Auto-Detection**: Automatically identifies source language using `langdetect`
- **âš¡ Fast Inference**: Uses distilled `nllb-200-distilled-600M` (600M parameters)
- **ğŸ¨ Simple Interface**: Clean Gradio UI for easy translation
- **ğŸ”„ Direct Translation**: Many-to-many translation without English as pivot

---

## ğŸš€ Live Demo

Try the translator now: **[Universal Translator on Hugging Face Spaces](https://huggingface.co/spaces/adeeliqbal/universal-translator)**

![UI Preview](assets/preview1.png)

---

## ğŸ—ï¸ Technical Architecture

The system implements a modular Seq2Seq pipeline:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Input  â”‚ --> â”‚ Language Detect  â”‚ --> â”‚ NLLB Transformerâ”‚ --> â”‚   Output   â”‚
â”‚  (Gradio)   â”‚     â”‚   + ISO Mapping  â”‚     â”‚  (Encoder-Dec)  â”‚     â”‚ (Gradio)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pipeline Stages

1. **Input Layer**: Captures raw text via Gradio interface
2. **Preprocessing & Detection**:
   - Text normalization (whitespace removal)
   - `langdetect` identifies ISO language code (e.g., `'ur'` for Urdu)
   - Maps ISO code â†’ NLLB token (e.g., `'ur'` â†’ `'urd_Arab'`)
3. **Inference Engine**:
   - NLLB-200 Transformer (Encoder-Decoder architecture)
   - Forced BOS tokens guide generation to target language
4. **Output Layer**: Returns decoded translation to UI

---

## ğŸ“‚ Project Structure

```bash
machine-translation-transformer/
â”œâ”€â”€ app.py                      # Main Gradio application
â”œâ”€â”€ machine_translation.ipynb   # Jupyter notebook with experiments
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # Project documentation
â””â”€â”€ assets/
    â””â”€â”€ preview1.png           # UI screenshot
```

---

## ğŸ› ï¸ Installation & Setup

### Prerequisites

- Python 3.8 or higher
- pip (Python Package Manager)
- 4GB+ RAM recommended

### Quick Start

1. **Clone the Repository**

```bash
git clone https://github.com/adeel-iqbal/machine-translation-transformer.git
cd machine-translation-transformer
```

2. **Install Dependencies**

```bash
pip install -r requirements.txt
```

3. **Run the Application**

```bash
python app.py
```

4. **Access the Interface**

Open your browser and navigate to: `http://127.0.0.1:7860`

---

## ğŸ§  Model Details

| Component | Specification |
|-----------|---------------|
| **Architecture** | Transformer (Sequence-to-Sequence) |
| **Checkpoint** | `facebook/nllb-200-distilled-600M` |
| **Parameters** | 600 Million |
| **Vocabulary** | 256k tokens (SentencePiece) |
| **Training Data** | FLORES-200 Dataset |
| **Languages** | 200+ (including low-resource) |

### Supported Languages (Sample)

- **English** (`eng_Latn`)
- **Urdu** (`urd_Arab`)
- **Hindi** (`hin_Deva`)
- **French** (`fra_Latn`)
- **German** (`deu_Latn`)
- **Spanish** (`spa_Latn`)
- **Chinese** (`zho_Hans`)
- **Arabic** (`ara_Arab`)

[View all supported languages in NLLB documentation](https://github.com/facebookresearch/fairseq/tree/nllb)

---

## ğŸ“Š Performance & Limitations

### âœ… Strengths

- **Speed**: CPU inference completes in <2 seconds for typical sentences
- **Quality**: High BLEU scores on FLORES-200 benchmark
- **Flexibility**: Direct translation between any language pair

### âš ï¸ Known Limitations

- **Context Length**: Optimized for sentence/paragraph-level translation (â‰¤512 tokens)
- **Auto-Detection**: May struggle with very short text (1-2 words) or code-mixed sentences
- **Domain**: General-purpose model; may need fine-tuning for specialized domains (medical, legal)

---

## ğŸ§ª Usage Example

```python
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline

# Load model
checkpoint = "facebook/nllb-200-distilled-600M"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)

# Create translator
translator = pipeline("translation", model=model, tokenizer=tokenizer, max_length=400)

# Translate (Urdu to English)
translator.model.config.forced_bos_token_id = tokenizer.convert_tokens_to_ids("eng_Latn")
output = translator("ÛŒÛ Ø§ÛŒÚ© Ù¹ÛŒØ³Ù¹ ÛÛ’", src_lang="urd_Arab", tgt_lang="eng_Latn")
print(output[0]['translation_text'])  # Output: "This is a test"
```
---

## ğŸ“š Citation & Acknowledgements

If you use this project in your research, please cite the original NLLB paper:

```bibtex
@article{nllb2022,
  author  = {NLLB Team, Meta AI},
  title   = {No Language Left Behind: Scaling Human-Centered Machine Translation},
  year    = {2022},
  journal = {arXiv preprint arXiv:2207.04672}
}
```

### Built With

- [Hugging Face Transformers](https://huggingface.co/transformers/) - Model implementation
- [Gradio](https://gradio.app/) - User interface framework
- [langdetect](https://github.com/Mimino666/langdetect) - Language detection
- [Meta AI NLLB](https://ai.facebook.com/research/no-language-left-behind/) - Core translation model

---

## ğŸ‘¨â€ğŸ’» Author

**Adeel Iqbal**

- GitHub: [@adeel-iqbal](https://github.com/adeel-iqbal)
- LinkedIn: [adeeliqbalmemon](https://linkedin.com/in/adeeliqbalmemon)
- Email: adeelmemon096@yahoo.com

---

## ğŸŒŸ Show Your Support

If you find this project helpful, please consider giving it a â­ on GitHub!

---

<p align="center">
  <i>Breaking language barriers, one translation at a time.</i>
</p>

<p align="center">
  Made with â¤ï¸ by <a href="https://github.com/adeel-iqbal">Adeel Iqbal</a>
</p>
